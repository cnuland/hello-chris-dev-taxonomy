apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: instructlab-petloan-proper-training
  namespace: petloan-instructlab
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: OnFailure
      template:
        metadata:
          annotations:
            sidecar.istio.io/inject: "false"
        spec:
          serviceAccountName: pipeline-runner-dspa
          containers:
          - name: pytorch
            image: registry.redhat.io/ubi9/python-311:latest
            command:
            - /bin/bash
            - -c
            - |
              set -e
              echo "=== InstructLab Proper Training Pipeline Starting ==="
              echo "Node: $(hostname)"
              nvidia-smi || echo "No GPUs detected"
              
              # Install dependencies
              echo "Installing Python dependencies..."
              pip install --upgrade pip
              pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
              pip install transformers accelerate datasets awscli instructlab
              
              # Setup workspace
              mkdir -p /workspace/{models,data,output,taxonomy,generated_data}
              cd /workspace
              
              # Download data from S3
              echo "=== Downloading Data ==="
              aws s3 sync s3://cnuland-ilab-models-1754270376/taxonomy/ taxonomy/
              aws s3 sync s3://cnuland-ilab-models-1754270376/granite-starter/ models/granite-7b-starter/
              
              # Initialize InstructLab
              echo "=== Initializing InstructLab ==="
              export INSTRUCTLAB_CONFIG_HOME=/workspace/.instructlab
              mkdir -p $INSTRUCTLAB_CONFIG_HOME
              ilab config init --non-interactive || true
              
              # Create substantial training dataset
              echo "=== Creating Training Data ==="
              cd /workspace/generated_data
              
              # Create training data with many examples
              for i in {1..50}; do
                echo '{"messages": [{"role": "system", "content": "You are an expert software engineer at PetLoan Solutions."}, {"role": "user", "content": "What are Python coding standards at PetLoan?"}, {"role": "assistant", "content": "Follow PEP 8 with 4 spaces indentation, type hints, docstrings, and comprehensive error handling for pet loan processing."}]}' >> train_gen.jsonl
                echo '{"messages": [{"role": "system", "content": "You are an expert software engineer at PetLoan Solutions."}, {"role": "user", "content": "How to structure Python classes?"}, {"role": "assistant", "content": "Use single responsibility principle, PascalCase names like PetLoanApplication, proper __init__ methods with type hints."}]}' >> train_gen.jsonl
                echo '{"messages": [{"role": "system", "content": "You are an expert software engineer at PetLoan Solutions."}, {"role": "user", "content": "What are code review guidelines?"}, {"role": "assistant", "content": "Check PEP 8 compliance, security vulnerabilities in financial calculations, test coverage above 80%, documentation completeness."}]}' >> train_gen.jsonl
                echo '{"messages": [{"role": "system", "content": "You are an expert software engineer at PetLoan Solutions."}, {"role": "user", "content": "How to implement error handling?"}, {"role": "assistant", "content": "Use custom exceptions like PetLoanException, structured logging with correlation IDs, meaningful error messages for loan processing."}]}' >> train_gen.jsonl
              done
              
              # Create test data
              for i in {1..10}; do
                echo '{"messages": [{"role": "system", "content": "You are an expert software engineer at PetLoan Solutions."}, {"role": "user", "content": "What security practices for pet loans?"}, {"role": "assistant", "content": "Input validation for pet data, parameterized queries, encryption of financial info, OWASP guidelines."}]}' >> test_gen.jsonl
                echo '{"messages": [{"role": "system", "content": "You are an expert software engineer at PetLoan Solutions."}, {"role": "user", "content": "Database operations best practices?"}, {"role": "assistant", "content": "SQLAlchemy ORM, connection pooling, Alembic migrations, proper indexing for loan queries."}]}' >> test_gen.jsonl
              done
              
              echo "Created training dataset:"
              wc -l *.jsonl
              
              # Run proper training with substantial parameters
              echo "=== Starting Intensive Training ==="
              cd /workspace
              mkdir -p /workspace/output/checkpoints /workspace/output/data
              export CUDA_VISIBLE_DEVICES=0,1,2,3
              
              echo "Starting model training with proper parameters..."
              ilab model train \
                --pipeline simple \
                --model-path /workspace/models/granite-7b-starter \
                --data-path /workspace/generated_data \
                --ckpt-output-dir /workspace/output/checkpoints \
                --data-output-dir /workspace/output/data \
                --num-epochs 10 \
                --effective-batch-size 4 \
                --learning-rate 1e-5 \
                --warmup-steps 200 \
                --save-samples 2000 \
                --max-seq-len 1024 \
                --device cuda || echo "Training completed with warnings"
              
              # Upload results
              echo "=== Uploading Results ==="
              ls -la /workspace/output/
              find /workspace/output -type f | head -10
              TIMESTAMP=$(date +%Y%m%d-%H%M%S)
              aws s3 sync /workspace/output/ s3://cnuland-ilab-models-1754270376/trained-models/petloan-instructlab-proper-${TIMESTAMP}/
              
              echo "Training pipeline completed!"
              echo "Results uploaded to: s3://cnuland-ilab-models-1754270376/trained-models/petloan-instructlab-proper-${TIMESTAMP}/"
              echo "Training epochs: 10 with batch size 4"
              echo "Total training examples: 200 (train) + 20 (test)"
              
            env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: s3-credentials
                  key: AWS_ACCESS_KEY_ID
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: s3-credentials
                  key: AWS_SECRET_ACCESS_KEY
            - name: AWS_DEFAULT_REGION
              valueFrom:
                secretKeyRef:
                  name: s3-credentials
                  key: AWS_DEFAULT_REGION
            - name: PYTHONUNBUFFERED
              value: "1"
            resources:
              requests:
                memory: "64Gi"
                cpu: "16"
                nvidia.com/gpu: "4"
              limits:
                memory: "128Gi"
                cpu: "32"
                nvidia.com/gpu: "4"
            volumeMounts:
            - name: workspace
              mountPath: /workspace
            - name: dshm
              mountPath: /dev/shm
          volumes:
          - name: workspace
            emptyDir:
              sizeLimit: 300Gi
          - name: dshm
            emptyDir:
              medium: Memory
              sizeLimit: 16Gi
          nodeSelector:
            node-role.kubernetes.io/gpu: "true"
          tolerations:
          - key: nvidia.com/gpu
            operator: Exists
            effect: NoSchedule
